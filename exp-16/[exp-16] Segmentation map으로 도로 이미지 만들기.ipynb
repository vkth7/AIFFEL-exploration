{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "19fJBaGh4GmM-oWpuazgmtHRH-oQ3LT4p",
      "authorship_tag": "ABX9TyMlnuUbg91MiOmEaNPwI9km",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkth7/AIFFEL-exploration/blob/main/exp-16/%5Bexp-16%5D%20Segmentation%20map%EC%9C%BC%EB%A1%9C%20%EB%8F%84%EB%A1%9C%20%EC%9D%B4%EB%AF%B8%EC%A7%80%20%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전 Pix2Pix 논문에서 제시한 결과 중에 아래와 같은 실험 결과가 있었습니다. 도로의 레이블 정보를 활용해 이미지를 생성해낸 결과입니다.\n",
        "<br><br>\n",
        "![](https://d3s0tskafalll9.cloudfront.net/media/images/p2p_result_seg.max-800x600.png)\n",
        "<br>\n",
        "\n",
        "이번 프로젝트는 위와 같은 데이터셋을 이용해 Pix2Pix를 학습시켜보는 것입니다. 데이터셋은 아래에서 다운로드할 수 있습니다.\n",
        "1000개의 학습용 이미지 및 5개의 평가 이미지를 포함합니다.\n",
        "<br><br>\n",
        "[cityscapes.zip](https://d3s0tskafalll9.cloudfront.net/media/documents/cityscapes.zip)\n",
        "<br><br>\n",
        "이전 포켓몬 데이터에서 사용했던 스케치와는 조금 다른 레이블 정보 이미지를 입력으로 사용하기 때문에, 전처리 과정에 대해 약간의 혼란이 있을 수 있지만 크게 다른 과정은 없습니다.\n",
        "\n",
        "아래 Tensroflow에서 제공하는 Pix2Pix 튜토리얼은 위 이미지와 비슷한 레이블 정보 이미지를 사용하기 때문에 좋은 참고 자료가 될 수 있을 것 같습니다.\n",
        "<br><br>\n",
        "프로젝트 시작에 어려움이 있다면 아래 튜토리얼을 참고하시면서 이번 프로젝트를 수행해 봅시다.\n",
        "\n",
        "(아래 튜토리얼은 Pix2Pix 구조를 Functional API를 이용해 구현하기 때문에 이번에 진행한 Subclassing 방법을 이용한 모델 구현과 비교하면서 구현 방법에 대해서도 공부해 보시길 추천드립니다)\n",
        "<br><br>\n",
        "\n",
        "- [Tensorflow Pix2Pix Tutorial](https://www.tensorflow.org/tutorials/generative/pix2pix?hl=ko)\n"
      ],
      "metadata": {
        "id": "MHt_p7slM3ry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트 수행\n",
        "---\n",
        "<br>\n",
        "\n",
        "프로젝트를 진행하면서 필수로 수행해야 할 사항은 다음과 같습니다.\n",
        "<br><br>\n",
        "1. 데이터에 한 가지 이상의 augmentation 방법을 적용하여 학습해 주세요.\n",
        "(어떠한 방법을 사용했는지 적어주세요.)\n",
        "2. 이전에 구현했던 두 개의 Generator 중 Encoder와 Decoder간에 skip connection이 있는 U-Net Generator를 사용해 주세요.\n",
        "3. 모델 학습 후, 학습된 Generator를 이용해 테스트합니다. 테스트 데이터는 다운로드했던 \"val\" 폴더 내 이미지를 사용해 주세요.\n",
        "4. 1개 이상의 이미지에 대해 테스트 과정을 거친 후 그 결과를 스케치, 생성된 사진, 실제 사진 순서로 나란히 시각화해 주세요.\n",
        "5. 모델을 충분히 학습하기에 시간이 부족할 수 있습니다. 적어도 10 epoch 이상 학습하며 중간 손실 값에 대한 로그를 남겨주세요. 좋은 결과를 얻기 위해선 긴 학습 시간이 필요하므로 테스트 결과는 만족스럽지 않아도 괜찮습니다."
      ],
      "metadata": {
        "id": "aqtrEgm-NYGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -qq '/content/drive/MyDrive/aiffel/exp17/cityscapes.zip'"
      ],
      "metadata": {
        "id": "RwCukhlLS4ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv2xKwan9x93"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Input, Model\n",
        "from tensorflow.keras import optimizers, losses\n",
        "from tensorflow import data\n",
        "from tensorflow import image\n",
        "from tensorflow.keras.preprocessing.image import random_rotation\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import imageio\n",
        "# import PIL\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content'"
      ],
      "metadata": {
        "id": "ZV-tS6y0RNx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(data_dir, 'cityscapes/train/')\n",
        "test_path = os.path.join(data_dir, 'cityscapes/val/')\n",
        "print(\"number of train examples :\", len(os.listdir(train_path)))  # 1000\n",
        "print(\"number of test examples :\", len(os.listdir(test_path)))  # 5"
      ],
      "metadata": {
        "id": "l94UT4yNRwzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train 데이터 셋 중 임의로 6장 선택해 시각화"
      ],
      "metadata": {
        "id": "5ZAjWBft0asd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "for i in range(0, 6):\n",
        "    f = train_path + os.listdir(train_path)[np.random.randint(800)]\n",
        "    img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
        "    plt.subplot(3,2,i+1)\n",
        "    plt.tight_layout()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "id": "kwCpJd_eS043"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 크기 확인"
      ],
      "metadata": {
        "id": "yKrS6oL_Jqkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = train_path + os.listdir(train_path)[0]\n",
        "img = cv2.imread(f, cv2.IMREAD_COLOR)\n",
        "print(img.shape)  # (256, 512, 3)"
      ],
      "metadata": {
        "id": "mNByv_YELIB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## normalize, denormalize 함수"
      ],
      "metadata": {
        "id": "MQZ7ezUnLUdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x):\n",
        "    x = tf.cast(x, tf.float32)\n",
        "    return (x/127.5) - 1\n",
        "\n",
        "def denormalize(x):\n",
        "    x = (x+1)*127.5\n",
        "    x = x.numpy()\n",
        "    return x.astype(np.uint8)"
      ],
      "metadata": {
        "id": "nutkpFhqLTxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 나누기(real_image, input_image)\n"
      ],
      "metadata": {
        "id": "cGxD8MyQKtDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_image(img, 3)\n",
        "    \n",
        "    w = tf.shape(img)[1] // 2\n",
        "    real_image = img[:, :w, :] \n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    input_image = img[:, w:, :] \n",
        "    input_image = tf.cast(input_image, tf.float32)\n",
        "    return normalize(input_image), normalize(real_image)\n",
        "\n",
        "f = train_path + os.listdir(train_path)[1]\n",
        "input_image, real_image = load_img(f)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.subplot(1,2,1); plt.imshow(denormalize(real_image))\n",
        "plt.subplot(1,2,2); plt.imshow(denormalize(input_image))"
      ],
      "metadata": {
        "id": "jrvE8sOdgTkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## augmentation 함수"
      ],
      "metadata": {
        "id": "laqbuvasLbgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function() # 빠른 텐서플로 연산을 위해 @tf.function()을 사용합니다. \n",
        "def apply_augmentation(input_image, real_image):\n",
        "    stacked = tf.concat([input_image, real_image], axis=-1)\n",
        "    \n",
        "    _pad = tf.constant([[30,30],[30,30],[0,0]])\n",
        "    if tf.random.uniform(()) < .5:\n",
        "        padded = tf.pad(stacked, _pad, \"REFLECT\")\n",
        "    else:\n",
        "        padded = tf.pad(stacked, _pad, \"CONSTANT\", constant_values=1.)\n",
        "\n",
        "    out = image.random_crop(padded, size=[256, 256, 6])\n",
        "    \n",
        "    out = image.random_flip_left_right(out)\n",
        "    out = image.random_flip_up_down(out)\n",
        "    \n",
        "    if tf.random.uniform(()) < .5:\n",
        "        degree = tf.random.uniform([], minval=1, maxval=4, dtype=tf.int32)\n",
        "        out = image.rot90(out, k=degree)\n",
        "    \n",
        "    return out[...,:3], out[...,3:]"
      ],
      "metadata": {
        "id": "XWUqK1XjgPFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## augmentation 적용 후 시각화"
      ],
      "metadata": {
        "id": "vTaYQLnxL4pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,13))\n",
        "img_n = 1\n",
        "for i in range(1, 13, 2):\n",
        "    augmented_input, augmented_real = apply_augmentation(input_image, real_image)\n",
        "    \n",
        "    plt.subplot(3,4,i)\n",
        "    plt.imshow(denormalize(augmented_input)); plt.title(f\"Image {img_n}\")\n",
        "    plt.subplot(3,4,i+1); \n",
        "    plt.imshow(denormalize(augmented_real)); plt.title(f\"Image {img_n}\")\n",
        "    img_n += 1"
      ],
      "metadata": {
        "id": "9A6GDv77gr6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전체 train 데이터 셋 augmentation 적용"
      ],
      "metadata": {
        "id": "pjzTkQuyL_yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train(img_path):\n",
        "    input_image, real_image = load_img(img_path)\n",
        "    input_image, real_image = apply_augmentation(input_image, real_image)\n",
        "    return input_image, real_image\n",
        "\n",
        "train_images = data.Dataset.list_files(train_path + \"*.jpg\")\n",
        "train_images = train_images.map(get_train).shuffle(100).batch(4)\n",
        "\n",
        "sample = train_images.take(1)\n",
        "sample = list(sample.as_numpy_iterator())\n",
        "input_image, real_image = (sample[0][0]+1)*127.5, (sample[0][1]+1)*127.5\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1); plt.imshow(input_image[0].astype(np.uint8))\n",
        "plt.subplot(1,2,2); plt.imshow(real_image[0].astype(np.uint8))"
      ],
      "metadata": {
        "id": "xxXDuDe2hCHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Block, Decode Block 구성"
      ],
      "metadata": {
        "id": "FqxRK5uIhhAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncodeBlock(layers.Layer):\n",
        "    def __init__(self, n_filters, use_bn=True):\n",
        "        super(EncodeBlock, self).__init__()\n",
        "        self.use_bn = use_bn       \n",
        "        self.conv = layers.Conv2D(n_filters, 4, 2, \"same\", use_bias=False)\n",
        "        self.batchnorm = layers.BatchNormalization()\n",
        "        self.lrelu = layers.LeakyReLU(0.2)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.use_bn:\n",
        "            x = self.batchnorm(x)\n",
        "        return self.lrelu(x)\n",
        "\n",
        "    \n",
        "class DecodeBlock(layers.Layer):\n",
        "    def __init__(self, f, dropout=True):\n",
        "        super(DecodeBlock, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.Transconv = layers.Conv2DTranspose(f, 4, 2, \"same\", use_bias=False)\n",
        "        self.batchnorm = layers.BatchNormalization()\n",
        "        self.relu = layers.ReLU()\n",
        "        \n",
        "    def call(self, x):\n",
        "        x = self.Transconv(x)\n",
        "        x = self.batchnorm(x)\n",
        "        if self.dropout:\n",
        "            x = layers.Dropout(.5)(x)\n",
        "        return self.relu(x)"
      ],
      "metadata": {
        "id": "WEHwP5WfhgMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## U-Net Generator 구현"
      ],
      "metadata": {
        "id": "AxUy0VschwpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNetGenerator(Model):\n",
        "    def __init__(self):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "        encode_filters = [64,128,256,512,512,512,512,512]\n",
        "        decode_filters = [512,512,512,512,256,128,64]\n",
        "        \n",
        "        self.encode_blocks = []\n",
        "        for i, f in enumerate(encode_filters):\n",
        "            if i == 0:\n",
        "                self.encode_blocks.append(EncodeBlock(f, use_bn=False))\n",
        "            else:\n",
        "                self.encode_blocks.append(EncodeBlock(f))\n",
        "        \n",
        "        self.decode_blocks = []\n",
        "        for i, f in enumerate(decode_filters):\n",
        "            if i < 3:\n",
        "                self.decode_blocks.append(DecodeBlock(f))\n",
        "            else:\n",
        "                self.decode_blocks.append(DecodeBlock(f, dropout=False))\n",
        "        \n",
        "        self.last_conv = layers.Conv2DTranspose(3, 4, 2, \"same\", use_bias=False)\n",
        "    \n",
        "    def call(self, x):\n",
        "        features = []\n",
        "        for block in self.encode_blocks:\n",
        "            x = block(x)\n",
        "            features.append(x)\n",
        "        \n",
        "        features = features[:-1]\n",
        "                    \n",
        "        for block, feat in zip(self.decode_blocks, features[::-1]):\n",
        "            x = block(x)\n",
        "            x = layers.Concatenate()([x, feat])\n",
        "        \n",
        "        x = self.last_conv(x)\n",
        "        return x\n",
        "                \n",
        "    def get_summary(self, input_shape=(256,256,3)):\n",
        "        inputs = Input(input_shape)\n",
        "        return Model(inputs, self.call(inputs)).summary()"
      ],
      "metadata": {
        "id": "tdP0GHzMh9Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = UNetGenerator()\n",
        "generator.get_summary()"
      ],
      "metadata": {
        "id": "LY58LMmViN_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Disk Block 구현"
      ],
      "metadata": {
        "id": "jLqMVjIbieQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiscBlock(layers.Layer):\n",
        "    def __init__(self, n_filters, stride=2, custom_pad=False, use_bn=True, act=True):\n",
        "        super(DiscBlock, self).__init__()\n",
        "        self.custom_pad = custom_pad\n",
        "        self.use_bn = use_bn\n",
        "        self.act = act\n",
        "        \n",
        "        if custom_pad:\n",
        "            self.padding = layers.ZeroPadding2D()\n",
        "            self.conv = layers.Conv2D(n_filters, 4, stride, \"valid\", use_bias=False)\n",
        "        else:\n",
        "            self.conv = layers.Conv2D(n_filters, 4, stride, \"same\", use_bias=False)\n",
        "        \n",
        "        self.batchnorm = layers.BatchNormalization() if use_bn else None\n",
        "        self.lrelu = layers.LeakyReLU(0.2) if act else None\n",
        "        \n",
        "    def call(self, x):\n",
        "        if self.custom_pad:\n",
        "            x = self.padding(x)\n",
        "            x = self.conv(x)\n",
        "        else:\n",
        "            x = self.conv(x)\n",
        "                \n",
        "        if self.use_bn:\n",
        "            x = self.batchnorm(x)\n",
        "            \n",
        "        if self.act:\n",
        "            x = self.lrelu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nBc49lJUigyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator 구현"
      ],
      "metadata": {
        "id": "b6iE7z_2ihnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(Model):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.block1 = layers.Concatenate()\n",
        "        self.block2 = DiscBlock(n_filters=64, stride=2, custom_pad=False, use_bn=False, act=True)\n",
        "        self.block3 = DiscBlock(n_filters=128, stride=2, custom_pad=False, use_bn=True, act=True)\n",
        "        self.block4 = DiscBlock(n_filters=256, stride=2, custom_pad=False, use_bn=True, act=True)\n",
        "        self.block5 = DiscBlock(n_filters=512, stride=1, custom_pad=True, use_bn=True, act=True)\n",
        "        self.block6 = DiscBlock(n_filters=1, stride=1, custom_pad=True, use_bn=False, act=False)\n",
        "        self.sigmoid = layers.Activation(\"sigmoid\")\n",
        "        \n",
        "    \n",
        "    def call(self, x, y):\n",
        "        out = self.block1([x, y])\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.block4(out)\n",
        "        out = self.block5(out)\n",
        "        out = self.block6(out)\n",
        "        return self.sigmoid(out)\n",
        "    \n",
        "    def get_summary(self, x_shape=(256,256,3), y_shape=(256,256,3)):\n",
        "        x, y = Input(x_shape), Input(y_shape) \n",
        "        return Model((x, y), self.call(x, y)).summary()"
      ],
      "metadata": {
        "id": "edjC0kAOitbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Discriminator()\n",
        "discriminator.get_summary()"
      ],
      "metadata": {
        "id": "4PFnMnnbjGDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실함수(BCE, MAE) 사용"
      ],
      "metadata": {
        "id": "HJKqK4zzjMh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bce = losses.BinaryCrossentropy(from_logits=False)\n",
        "mae = losses.MeanAbsoluteError()\n",
        "\n",
        "def get_gene_loss(fake_output, real_output, fake_disc):\n",
        "    l1_loss = mae(real_output, fake_output)\n",
        "    gene_loss = bce(tf.ones_like(fake_disc), fake_disc)\n",
        "    return gene_loss, l1_loss\n",
        "\n",
        "def get_disc_loss(fake_disc, real_disc):\n",
        "    return bce(tf.zeros_like(fake_disc), fake_disc) + bce(tf.ones_like(real_disc), real_disc)"
      ],
      "metadata": {
        "id": "pbR6EOxpjOWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer 설정"
      ],
      "metadata": {
        "id": "fnlu8F0vjbBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gene_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)\n",
        "disc_opt = optimizers.Adam(2e-4, beta_1=.5, beta_2=.999)"
      ],
      "metadata": {
        "id": "r2K3IAEbjf9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가중치 업데이트 함수"
      ],
      "metadata": {
        "id": "0AISilaJjfmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(input_image, real_image):\n",
        "    with tf.GradientTape() as gene_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generator 예측\n",
        "        generated_image = generator(input_image, training=True)\n",
        "        # Discriminator 예측\n",
        "        fake_disc = discriminator(input_image, generated_image, training=True)\n",
        "        real_disc = discriminator(input_image, real_image, training=True)\n",
        "        # Generator 손실 계산\n",
        "        gene_loss, l1_loss = get_gene_loss(generated_image, real_image, fake_disc)\n",
        "        gene_total_loss = gene_loss + (100 * l1_loss) ## <===== L1 손실 반영 λ=100\n",
        "        # Discrminator 손실 계산\n",
        "        disc_loss = get_disc_loss(fake_disc, real_disc)\n",
        "                \n",
        "    gene_gradient = gene_tape.gradient(gene_total_loss, generator.trainable_variables)\n",
        "    disc_gradient = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    \n",
        "    gene_opt.apply_gradients(zip(gene_gradient, generator.trainable_variables))\n",
        "    disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
        "    return gene_loss, l1_loss, disc_loss\n"
      ],
      "metadata": {
        "id": "YwGb3LKAvMlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 생성된 이미지 저장"
      ],
      "metadata": {
        "id": "I9xvqaDfvNRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, it, save_file_num=1):\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    for train_idx in range(len(os.listdir(train_path))//10):\n",
        "        f = train_path + os.listdir(train_path)[train_idx]\n",
        "        input_image, real_image = load_img(f)\n",
        "\n",
        "        pred = generator(tf.expand_dims(input_image, 0))\n",
        "        pred = denormalize(pred)\n",
        "\n",
        "        # 100개의 sample -> 10행 10열로 plot\n",
        "        plt.subplot(10, 10, train_idx+1)\n",
        "        plt.imshow(pred[0])\n",
        "        plt.axis('off')\n",
        "\n",
        "    # subplot 간격 자동 조절\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_file_path = os.path.join(data_dir, 'cityscapes/generated_samples/sample_{}'.format(save_file_num))\n",
        "    if not os.path.exists(save_file_path):\n",
        "        os.makedirs(save_file_path)\n",
        "    \n",
        "    save_file_path = os.path.join(save_file_path, 'sample_epoch_{:04d}_iter_{:03d}.png'.format(epoch, it))\n",
        "    plt.savefig(save_file_path)  # 이미지 저장\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "n7DUYqH1vURH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## history 그리는 함수(ex 11 참고)"
      ],
      "metadata": {
        "id": "3vKPQsXaXHin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_train_history(history, epoch, save_file_num=1):\n",
        "    plt.figure(figsize=(15,15))\n",
        "\n",
        "    plt.subplot(411)  \n",
        "    plt.plot(history['gen_loss'])  \n",
        "    plt.plot(history['disc_loss'])  \n",
        "    plt.plot(history['l1_loss'])  \n",
        "    plt.title('model loss')  \n",
        "    plt.ylabel('loss')  \n",
        "    plt.xlabel('batch iters')  \n",
        "    plt.legend(['gen_loss', 'disc_loss'], loc='upper left')\n",
        "\n",
        "    plt.subplot(412)  \n",
        "    plt.plot(history['gen_loss'], 'tab:blue')   \n",
        "    plt.title('gen_loss')  \n",
        "    plt.ylabel('loss')  \n",
        "    plt.xlabel('batch iters')  \n",
        "    plt.legend(['gen_loss'], loc='upper left')\n",
        "\n",
        "    plt.subplot(413)  \n",
        "    plt.plot(history['l1_loss'], 'tab:green')   \n",
        "    plt.title('l1_loss')  \n",
        "    plt.ylabel('loss')  \n",
        "    plt.xlabel('batch iters')  \n",
        "    plt.legend(['l1_loss'], loc='upper left')  \n",
        "\n",
        "    plt.subplot(414)  \n",
        "    plt.plot(history['disc_loss'], 'tab:orange')   \n",
        "    plt.title('disc_loss')  \n",
        "    plt.ylabel('loss')  \n",
        "    plt.xlabel('batch iters')  \n",
        "    plt.legend(['disc_loss'], loc='upper left')  \n",
        "\n",
        "    # subplot 간격 자동 조절\n",
        "    plt.tight_layout()  \n",
        "\n",
        "    # training_history 디렉토리에 epoch별로 그래프를 이미지 파일로 저장합니다.\n",
        "    save_file_path = os.path.join(data_dir, 'cityscapes/training_history/training_history_{}'.format(save_file_num))\n",
        "    if not os.path.exists(save_file_path):\n",
        "        os.makedirs(save_file_path)\n",
        "        \n",
        "    # 이미지 저장\n",
        "    save_file_path = os.path.join(save_file_path, 'training_history_{:04d}.png'.format(epoch))\n",
        "    plt.savefig(save_file_path)  \n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2LMvs8P6VVrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checkpoint 설정"
      ],
      "metadata": {
        "id": "5h12j9SqXYeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.train.Checkpoint(generator_optimizer=gene_opt,\n",
        "                                 discriminator_optimizer=disc_opt,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "metadata": {
        "id": "jqMdJwypVcS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training 함수"
      ],
      "metadata": {
        "id": "Pf1hNTT3XcD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, epochs, save_every, save_file_num=1):\n",
        "    start = time.time()\n",
        "    history = {'gen_loss':[], 'l1_loss':[], 'disc_loss':[]}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        for it, (input_image, ground_truth) in enumerate(train_images):\n",
        "            g_loss, l1_loss, d_loss = train_step(input_image, ground_truth)\n",
        "            history['gen_loss'].append(g_loss)\n",
        "            history['l1_loss'].append(l1_loss)\n",
        "            history['disc_loss'].append(d_loss)\n",
        "\n",
        "            # 100회 반복할 때마다 손실 출력\n",
        "            if (i + 1) % 100 == 0:\n",
        "                display.clear_output(wait=True)\n",
        "                generate_and_save_images(generator, epoch+1, it+1, save_file_num)\n",
        "                print(f\"EPOCH[{epoch}] - STEP[{i+1}] \\\n",
        "                      \\nGenerator_loss:{g_loss.numpy():.4f} \\\n",
        "                      \\nL1_loss:{l1_loss.numpy():.4f} \\\n",
        "                      \\nDiscriminator_loss:{d_loss.numpy():.4f}\", end=\"\\n\\n\")\n",
        "\n",
        "        if (epoch + 1) % save_every == 0:\n",
        "            checkpoint_dir = os.path.join(data_dir, 'cityscapes/training_checkpoints/training_checkpoints_{}'.format(save_file_num))\n",
        "            checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator, epochs, it, save_file_num)\n",
        "        print('Time for training : {} sec'.format(int(time.time()-start)))\n",
        "\n",
        "        draw_train_history(history, epoch, save_file_num)"
      ],
      "metadata": {
        "id": "eS--lZzxXcjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 진행"
      ],
      "metadata": {
        "id": "YmaHLe0viiMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장 간격\n",
        "save_every = 10 \n",
        "\n",
        "# 학습 횟수\n",
        "EPOCHS = 100  \n",
        "\n",
        "save_file_num = 1"
      ],
      "metadata": {
        "id": "1AGUEo_EihOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train(train_images, EPOCHS, save_every, save_file_num)"
      ],
      "metadata": {
        "id": "Xt_Wdvskiq5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gif 생성"
      ],
      "metadata": {
        "id": "2urzP53Pivzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gif(anim_file_num=1):\n",
        "\n",
        "    anim_file = '/content/drive/MyDrive/aiffel/exp17/Pix2Pix_{}.gif'.format(anim_file_num)\n",
        "    # generated Images\n",
        "    filenames = glob.glob('/content/cityscapes/generated_samples/sample_{}/sample*.png'.format(anim_file_num))  \n",
        "   \n",
        "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "        filenames = sorted(filenames)\n",
        "        last = -1\n",
        "        for i, filename in enumerate(filenames):\n",
        "            frame = 2*(i**0.5)\n",
        "            if round(frame) > round(last):\n",
        "                last = frame\n",
        "            else:\n",
        "                continue\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)"
      ],
      "metadata": {
        "id": "PeWxOJNsixu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_gif(1)"
      ],
      "metadata": {
        "id": "dp0N-KIBluR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## checkpoint 불러와서 출력 확인"
      ],
      "metadata": {
        "id": "fmG91pJkl5we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_training_checkpoints_image(save_file_num=1):\n",
        "    checkpoint_dir = os.path.join(data_dir, 'cityscapes/training_checkpoints/training_checkpoints_{}'.format(save_file_num))\n",
        "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "    checkpoint.restore(latest)\n",
        "\n",
        "    generator = checkpoint.generator\n",
        "    discriminator = checkpoint.discriminator\n",
        "\n",
        "    # 로드한 모델이 정상적으로 이미지를 생성하는지 확인해 봅니다. \n",
        "    for test_idx in range(len(os.listdir(test_path))):\n",
        "        f = test_path + os.listdir(test_path)[test_idx]\n",
        "        input_image, real_image = load_img(f)\n",
        "\n",
        "        pred = generator(tf.expand_dims(input_image, 0))\n",
        "        pred = denormalize(pred)\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        \n",
        "        plt.subplot(1,3,1); plt.axis('off'); plt.imshow(denormalize(input_image)); plt.title('Input Image')\n",
        "        plt.subplot(1,3,2); plt.axis('off'); plt.imshow(pred[0]); plt.title('Predicted Image', fontsize=20)\n",
        "        plt.subplot(1,3,3); plt.axis('off'); plt.imshow(denormalize(real_image)); plt.title('Ground Truth')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "Xw3npnBTlQ4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_training_checkpoints_image(1)"
      ],
      "metadata": {
        "id": "yYCr8D3QmBeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 결과 확인"
      ],
      "metadata": {
        "id": "UKqJEwvwimiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_images(model):\n",
        "\n",
        "    plt.figure(figsize=(40,20))\n",
        "    for test_idx in range(len(os.listdir(test_path))):\n",
        "        f = test_path + os.listdir(test_path)[test_idx]\n",
        "        input_image, real_image = load_img(f)\n",
        "\n",
        "        pred = generator(tf.expand_dims(input_image, 0))\n",
        "        pred = denormalize(pred)\n",
        "\n",
        "        # 5개의 test sample이라 5행 1열로 시각화\n",
        "        plt.subplot(5, 1, test_idx+1)\n",
        "        \n",
        "        plt.imshow(pred[0])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "toHde2MBEO0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_images(generator)"
      ],
      "metadata": {
        "id": "BbWoNDkBGx6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "루브릭\n",
        "\n",
        "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
        "\n",
        "평가문항\t상세기준\n",
        "1. pix2pix 모델 학습을 위해 필요한 데이터셋을 적절히 구축하였다.\n",
        "\n",
        "  데이터 분석 과정 및 한 가지 이상의 augmentation을 포함한 데이터셋 구축 과정이 체계적으로 제시되었다.\n",
        "2. pix2pix 모델을 구현하여 성공적으로 학습 과정을 진행하였다.\n",
        "\n",
        "  U-Net generator, discriminator 모델 구현이 완료되어 train_step의 output을 확인하고 개선하였다.\n",
        "3. 학습 과정 및 테스트에 대한 시각화 결과를 제출하였다.\n",
        "\n",
        "  10 epoch 이상의 학습을 진행한 후 최종 테스트 결과에서 진행한 epoch 수에 걸맞은 정도의 품질을 확인하였다."
      ],
      "metadata": {
        "id": "Rs7r9ioJNm3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고\n",
        "- 이번 프로젝트에서 어려웠던 점\n",
        "  - exp-11에서 했던 gif로 저장하는 것을 이번 익스에 맞게 변환 시키는 것이 힘들었습니다.\n",
        "  - load_img() 함수에서 return 값의 순서와 get_trai() 함수에서 load_img() 함수를 썼는데, input_image와 real_image를 바꿔 저장하여 generator가 Input Image와 비슷한 사진을 출력하였습니다."
      ],
      "metadata": {
        "id": "ga7haJ_VE3iD"
      }
    }
  ]
}