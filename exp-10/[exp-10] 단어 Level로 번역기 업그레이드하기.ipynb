{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[exp-10] 단어 Level로 번역기 업그레이드하기.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1apAa_6aTTpmQzAvh_VaNzQEyLXSKfz9f",
      "authorship_tag": "ABX9TyN1AwZpBVFgT1nv+SD29pil",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkth7/AIFFEL-exploration/blob/main/exp-10/%5Bexp-10%5D%20%EB%8B%A8%EC%96%B4%20Level%EB%A1%9C%20%EB%B2%88%EC%97%AD%EA%B8%B0%20%EC%97%85%EA%B7%B8%EB%A0%88%EC%9D%B4%EB%93%9C%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 프로젝트 : 단어 Level로 번역기 업그레이드하기"
      ],
      "metadata": {
        "id": "x8BG6uFU13-z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO_3F-Yp0unh",
        "outputId": "4d0c1668-9eed-42de-9692-8e26edcd9f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-19 06:40:54--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6612164 (6.3M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   6.31M  7.24MB/s    in 0.9s    \n",
            "\n",
            "2022-08-19 06:40:56 (7.24 MB/s) - ‘fra-eng.zip’ saved [6612164/6612164]\n",
            "\n",
            "mv: target 'Notebooks/exp-10' is not a directory\n",
            "/bin/bash: line 0: cd: too many arguments\n"
          ]
        }
      ],
      "source": [
        "# !wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv fra-eng.zip  /content/drive/MyDrive/Colab\\ Notebooks/exp-10"
      ],
      "metadata": {
        "id": "2EH2p0mh1bpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/drive/MyDrive/Colab\\ Notebooks/exp-10 && unzip fra-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_DK79TF1dX2",
        "outputId": "88428883-792f-48e6-bac4-10b94bff955e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nf60gP-J57W3",
        "outputId": "5a1fdaf5-8636-46bf-b973-d568ec2d722d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be upgraded:\n",
            "  libcudnn8\n",
            "1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 3,139 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 7s (62.8 MB/s)\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n",
            "(Reading database ... 155654 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.0 kB/s \n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 61.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 70.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.2+zzzcolab20220719082949\n",
            "    Uninstalling tensorflow-2.8.2+zzzcolab20220719082949:\n",
            "      Successfully uninstalled tensorflow-2.8.2+zzzcolab20220719082949\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습에서 구현한 번역기는 글자 단위(Character-level)에서 구현된 번역기였습니다. 하지만 실제 번역기의 경우에는 글자 단위가 아니라 단어 단위(Word-level)에서 구현되는 것이 좀 더 보편적입니다.\n",
        "\n",
        "동일한 데이터셋을 사용하면서 글자 단위와는 다른 전처리와 임베딩 층(Embedding layer)를 추가하여 단어 단위의 번역기를 완성시켜보겠습니다. 하지만, 단어 단위로 할 경우에는 단어의 개수가 글자 단위로 했을 경우와 비교하여 단어장의 크기(Vocabulary) 크기도 커지고, 학습 속도도 좀 더 느려집니다. 학습과 테스트 시의 원활한 진행을 위해서 **데이터에서 상위 33,000개의 샘플만 사용해주세요.**\n",
        "\n",
        "**33000개 중 3000개는 테스트 데이터로 분리하여 모델을 학습한 후에 번역을 테스트 하는 용도로 사용합니다.**"
      ],
      "metadata": {
        "id": "YWoZvNSSYF34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1. 정제, 정규화, 전처리 (영어, 프랑스어 모두!)**\n",
        "\n",
        "---\n",
        "\n",
        "글자 단위가 아닌 단어 단위의 번역기를 하기 위해서는 글자 단위에서는 신경쓰지 않았던 몇 가지 추가적인 전처리가 필요합니다.\n",
        "\n",
        "1. **구두점(Punctuation)을 단어와 분리해주세요.**\n",
        "\n",
        "일반적으로 영어권 언어의 경우에는 띄어쓰기 단위로 단어를 분리합니다. 토큰화(Tokenization)이라고도 불리는 이 작업은 어디서부터 어디까지가 하나의 단어인지를 구분하는 작업인데요. 그런데 띄어쓰기를 해주기 전에 구두점을 분리하는 작업이 필요할 때가 있습니다.\n",
        "\n",
        "예를 들어서 'he is a good boy!'라는 문장이 있을 때, 이를 띄어쓰기 단위로 토큰화한다면\n",
        "\n",
        "['he', 'is', 'a', 'good', 'boy!']가 됩니다. 그런데 실제로 !는 boy와 붙어있는 한 단어가 아니므로\n",
        "\n",
        "좀 더 올바른 전처리는 ['he', 'is', 'a', 'good', 'boy', '!']가 맞습니다.\n",
        "\n",
        "!나 ? 또는 온점과 같은 특수문자들을 구두점(punctuation)이라고 부릅니다.\n",
        "\n",
        "이들을 토큰화하기 전에 단어와 미리 분리시켜주세요!\n",
        "\n",
        "분리 전 : he is a Good boy!\n",
        "\n",
        "분리 후 : he is a Good boy !\n",
        "\n",
        "2. **소문자로 바꿔주세요.**\n",
        "\n",
        "기계가 보기에는 스펠링이 같더라도 대문자로 된 단어와 소문자로 된 단어는 서로 다른 단어입니다. 예를 들어 'Good'과 'good'은 기계가 보기에는 다른 단어입니다. 그래서 모든 문장에 대해서 전부 영어로 바꿔주는 작업을 하겠습니다.\n",
        "\n",
        "변환 전 : he is a Good boy !\n",
        "\n",
        "변환 후 : he is a good boy !\n",
        "\n",
        "3. **띄어쓰기 단위로 토큰를 수행하세요.**\n",
        "\n",
        "띄어쓰기 단위로 토큰화를 수행해서 단어를 분리하는 작업을 해주세요. 기계는 이렇게 분리된 토큰들을 각각 하나의 단어로 인식할 수 있게 됩니다.\n",
        "\n",
        "토큰화 전 : 'he is a good boy !'\n",
        "\n",
        "토큰화 후 : ['he', 'is', 'a', 'good', 'boy', '!']"
      ],
      "metadata": {
        "id": "Of2PJE3RYMBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "PkjF_01Y2Bat"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/exp-10/fra.txt'\n",
        "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "myjf0vl52F0p",
        "outputId": "012159e1-2914-47d9-944e-88a66e5b0ef9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 194513\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   eng  \\\n",
              "137148              You have a good chance of winning.   \n",
              "35583                             I have a pretty dog.   \n",
              "175374  The police are looking into his disappearance.   \n",
              "76639                       Don't forget to add me in.   \n",
              "154884          Will the work be finished by tomorrow?   \n",
              "\n",
              "                                                      fra  \\\n",
              "137148              Vous avez une bonne chance de gagner.   \n",
              "35583                                 J'ai un beau chien.   \n",
              "175374  La police est en train d'enquêter sur sa dispa...   \n",
              "76639                        N'oublie pas de m'y ajouter.   \n",
              "154884         L’œuvre sera-t-elle achevée d'ici demain ?   \n",
              "\n",
              "                                                       cc  \n",
              "137148  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "35583   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "175374  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
              "76639   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
              "154884  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f09de18-fb33-43ce-b77f-a811ab79f3dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>137148</th>\n",
              "      <td>You have a good chance of winning.</td>\n",
              "      <td>Vous avez une bonne chance de gagner.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35583</th>\n",
              "      <td>I have a pretty dog.</td>\n",
              "      <td>J'ai un beau chien.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175374</th>\n",
              "      <td>The police are looking into his disappearance.</td>\n",
              "      <td>La police est en train d'enquêter sur sa dispa...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76639</th>\n",
              "      <td>Don't forget to add me in.</td>\n",
              "      <td>N'oublie pas de m'y ajouter.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154884</th>\n",
              "      <td>Will the work be finished by tomorrow?</td>\n",
              "      <td>L’œuvre sera-t-elle achevée d'ici demain ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f09de18-fb33-43ce-b77f-a811ab79f3dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f09de18-fb33-43ce-b77f-a811ab79f3dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f09de18-fb33-43ce-b77f-a811ab79f3dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines = lines[['eng', 'fra']][:33000] # 3만3천개 샘플 사용\n",
        "lines.sample(5)"
      ],
      "metadata": {
        "id": "8KCWf09V2pjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "94979a5b-00b5-42b0-cf84-4a9e87056384"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       eng                        fra\n",
              "8488        That's a fake.             C'est un faux.\n",
              "8337        She is French.        Elle est française.\n",
              "23408   I also went there.  J'y suis également allée.\n",
              "24093   I pruned the tree.       J'ai élagué l'arbre.\n",
              "32143  Tom became popular.  Tom est devenu populaire."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd91f622-e276-4218-b466-291e9bed2dff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8488</th>\n",
              "      <td>That's a fake.</td>\n",
              "      <td>C'est un faux.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8337</th>\n",
              "      <td>She is French.</td>\n",
              "      <td>Elle est française.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23408</th>\n",
              "      <td>I also went there.</td>\n",
              "      <td>J'y suis également allée.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24093</th>\n",
              "      <td>I pruned the tree.</td>\n",
              "      <td>J'ai élagué l'arbre.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32143</th>\n",
              "      <td>Tom became popular.</td>\n",
              "      <td>Tom est devenu populaire.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd91f622-e276-4218-b466-291e9bed2dff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd91f622-e276-4218-b466-291e9bed2dff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd91f622-e276-4218-b466-291e9bed2dff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# 입력된 문장을\n",
        "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "#     2. 특수문자 양쪽에 공백을 넣고\n",
        "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "#     4. 다시 양쪽 공백을 지웁니다\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower() # 1\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
        "    sentence = sentence.strip() # 4\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "OqitDOZUYACh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines.fra = lines.fra.apply(lambda x : preprocess_sentence(x))\n",
        "lines.eng = lines.eng.apply(lambda x : preprocess_sentence(x))"
      ],
      "metadata": {
        "id": "kDMPIpLzhDfC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시작 토큰과 종료 토큰 추가\n",
        "sos_token = '\\t'\n",
        "eos_token = '\\n'\n",
        "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5)"
      ],
      "metadata": {
        "id": "9u4cBJVa2xF8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "154d6b4e-ca7d-4cd6-9343-156cd988d411"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 33000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       eng                               fra\n",
              "3461         i'm through .           \\t j'en ai terminé . \\n\n",
              "8761       tom is ok now .  \\t thomas est ok maintenant . \\n\n",
              "24037  i need to do that .          \\t je dois faire ça . \\n\n",
              "6388        will tom die ?        \\t tom va-t-il mourir ? \\n\n",
              "11851     they were dead .         \\t ils étaient morts . \\n"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a93705e-6af7-49e4-a36f-47e7d5f3a18f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3461</th>\n",
              "      <td>i'm through .</td>\n",
              "      <td>\\t j'en ai terminé . \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8761</th>\n",
              "      <td>tom is ok now .</td>\n",
              "      <td>\\t thomas est ok maintenant . \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24037</th>\n",
              "      <td>i need to do that .</td>\n",
              "      <td>\\t je dois faire ça . \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6388</th>\n",
              "      <td>will tom die ?</td>\n",
              "      <td>\\t tom va-t-il mourir ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>they were dead .</td>\n",
              "      <td>\\t ils étaient morts . \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a93705e-6af7-49e4-a36f-47e7d5f3a18f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a93705e-6af7-49e4-a36f-47e7d5f3a18f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a93705e-6af7-49e4-a36f-47e7d5f3a18f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines.fra = lines.fra.str.split(' ')\n",
        "lines.eng = lines.eng.str.split(' ')\n",
        "lines.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tGoYieZ1a1qJ",
        "outputId": "d3cf8c6c-1b92-4631-9ca7-764c1654bda2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       eng                  fra\n",
              "0  [go, .]      [\\t, va, !, \\n]\n",
              "1  [go, .]  [\\t, marche, ., \\n]\n",
              "2  [go, .]   [\\t, bouge, !, \\n]\n",
              "3  [hi, .]   [\\t, salut, !, \\n]\n",
              "4  [hi, .]   [\\t, salut, ., \\n]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98872137-b9f0-4c5a-b869-da92e4d7d1a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[go, .]</td>\n",
              "      <td>[\\t, va, !, \\n]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[go, .]</td>\n",
              "      <td>[\\t, marche, ., \\n]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[go, .]</td>\n",
              "      <td>[\\t, bouge, !, \\n]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[hi, .]</td>\n",
              "      <td>[\\t, salut, !, \\n]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[hi, .]</td>\n",
              "      <td>[\\t, salut, ., \\n]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98872137-b9f0-4c5a-b869-da92e4d7d1a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98872137-b9f0-4c5a-b869-da92e4d7d1a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98872137-b9f0-4c5a-b869-da92e4d7d1a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenizer = Tokenizer(char_level=True)   # 단어 단위로 Tokenizer를 생성\n",
        "eng_tokenizer.fit_on_texts(lines.eng)               # 30000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
        "input_text[:3]"
      ],
      "metadata": {
        "id": "7IVw-mYU2ysU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bea772-ab6d-4b24-c1be-37e5b6a65fa5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[26, 1], [26, 1], [26, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fra_tokenizer = Tokenizer(char_level=True)   # 문자 단위로 Tokenizer를 생성합니다. \n",
        "fra_tokenizer.fit_on_texts(lines.fra)                 # 50000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
        "target_text[:3]"
      ],
      "metadata": {
        "id": "Q7e-8MWC3UCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a2de4e-ba92-4c77-c44f-65e913e222d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 63, 7, 2], [1, 370, 3, 2], [1, 728, 7, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
      ],
      "metadata": {
        "id": "REWTJ9ny3WDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68be55f9-cb6d-43c0-e679-16afd67018d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 단어장의 크기 : 4809\n",
            "프랑스어 단어장의 크기 : 10879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_fra_seq_len = max([len(line) for line in target_text])"
      ],
      "metadata": {
        "id": "u2jVJLIr3XHh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('전체 샘플의 수 :',len(lines))\n",
        "print('영어 단어장의 크기 :', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
      ],
      "metadata": {
        "id": "R1D5Dpom3ZGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f49239-9f0b-475a-99d6-af6ee5ac6e55"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플의 수 : 33000\n",
            "영어 단어장의 크기 : 4809\n",
            "프랑스어 단어장의 크기 : 10879\n",
            "영어 시퀀스의 최대 길이 8\n",
            "프랑스어 시퀀스의 최대 길이 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = input_text\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
      ],
      "metadata": {
        "id": "_aTZFzU93dlk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_input[:3])\n",
        "print(decoder_target[:3])"
      ],
      "metadata": {
        "id": "TrebuXxZ3e1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d27d290e-57ed-4de6-c5ed-0185c7981c53"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 63, 7], [1, 370, 3], [1, 728, 7]]\n",
            "[[63, 7, 2], [370, 3, 2], [728, 7, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
        "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
      ],
      "metadata": {
        "id": "vNW78rPz3hMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e9f25d-8344-4da1-960c-526122c5b128"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 데이터의 크기(shape) : (33000, 8)\n",
            "프랑스어 입력데이터의 크기(shape) : (33000, 15)\n",
            "프랑스어 출력데이터의 크기(shape) : (33000, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
        "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
        "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
      ],
      "metadata": {
        "id": "29uuQSOL3pRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cead122b-f3bd-4f43-d485-f2e0ace51ed7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 학습데이터의 크기(shape) : (33000, 8)\n",
            "프랑스어 학습 입력데이터의 크기(shape) : (33000, 15)\n",
            "프랑스어 학습 출력데이터의 크기(shape) : (33000, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "hidden_units = 64"
      ],
      "metadata": {
        "id": "WD7TITUqv2Rq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(eng_vocab_size, embedding_dim)(encoder_inputs) # 임베딩 층\n",
        "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
        "encoder_lstm = LSTM(units=hidden_units, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
        "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
      ],
      "metadata": {
        "id": "ZUwQVlZNv5UT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 입력 텐서 생성.\n",
        "# encoder_inputs = Input(shape=(None,))\n",
        "# # hidden size가 256인 인코더의 LSTM 셀 생성\n",
        "# encoder_lstm = LSTM(units = 256, return_state = True)\n",
        "# # 디코더로 전달할 hidden state, cell state를 리턴. encoder_outputs은 여기서는 불필요.\n",
        "# encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# # hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장.\n",
        "# encoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "RCUaW8iA4r9x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(fra_vocab_size, hidden_units) # 임베딩 층\n",
        "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
        "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
        "\n",
        "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
        "decoder_lstm = LSTM(units=hidden_units, return_sequences=True, return_state=True) \n",
        "\n",
        "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
        "\n",
        "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
        "decoder_dense = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "LzIcrAYIwTAC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 입력 텐서 생성.\n",
        "# decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
        "# # hidden size가 256인 인코더의 LSTM 셀 생성\n",
        "# decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
        "# # decoder_outputs는 모든 time step의 hidden state\n",
        "# decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state = encoder_states)"
      ],
      "metadata": {
        "id": "NZNmG0Im4sp7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "metadata": {
        "id": "f64vusC-4uOD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "FjBjsJW_427N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92355b4-14cf-4293-ddb8-d418e1bc57c8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 64)     307776      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     696256      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " masking (Masking)              (None, None, 64)     0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " masking_1 (Masking)            (None, None, 64)     0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 64),         33024       ['masking[0][0]']                \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 64),   33024       ['masking_1[0][0]',              \n",
            "                                 (None, 64),                      'lstm[0][1]',                   \n",
            "                                 (None, 64)]                      'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 10879)  707135      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 10879)  118363520   ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 120,140,735\n",
            "Trainable params: 120,140,735\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
        "          batch_size=128, epochs=50)"
      ],
      "metadata": {
        "id": "HmXic6FO44g8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d71c625-e1a8-4d8d-e8da-06ead41df0fc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 75s 255ms/step - loss: 8.8600 - accuracy: 0.6232 - val_loss: 8.4444 - val_accuracy: 0.5836\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 8.0453 - accuracy: 0.6259 - val_loss: 7.7037 - val_accuracy: 0.5836\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 7.2990 - accuracy: 0.6259 - val_loss: 6.9926 - val_accuracy: 0.5836\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 6.5843 - accuracy: 0.6259 - val_loss: 6.3195 - val_accuracy: 0.5836\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 5.9094 - accuracy: 0.6259 - val_loss: 5.6928 - val_accuracy: 0.5836\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 5.2759 - accuracy: 0.6259 - val_loss: 5.1077 - val_accuracy: 0.5836\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 4.6795 - accuracy: 0.6259 - val_loss: 4.5604 - val_accuracy: 0.5836\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 4.1323 - accuracy: 0.6259 - val_loss: 4.0774 - val_accuracy: 0.5836\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 3.6569 - accuracy: 0.6259 - val_loss: 3.6697 - val_accuracy: 0.5836\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 3.2528 - accuracy: 0.6259 - val_loss: 3.3410 - val_accuracy: 0.5836\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.9461 - accuracy: 0.6259 - val_loss: 3.1225 - val_accuracy: 0.5836\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.7571 - accuracy: 0.6259 - val_loss: 3.0165 - val_accuracy: 0.5836\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6709 - accuracy: 0.6259 - val_loss: 2.9917 - val_accuracy: 0.5836\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6472 - accuracy: 0.6259 - val_loss: 2.9872 - val_accuracy: 0.5836\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6412 - accuracy: 0.6259 - val_loss: 2.9883 - val_accuracy: 0.5836\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6394 - accuracy: 0.6259 - val_loss: 2.9911 - val_accuracy: 0.5836\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6397 - accuracy: 0.6259 - val_loss: 2.9963 - val_accuracy: 0.5836\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6408 - accuracy: 0.6259 - val_loss: 3.0012 - val_accuracy: 0.5836\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6427 - accuracy: 0.6259 - val_loss: 3.0071 - val_accuracy: 0.5836\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6448 - accuracy: 0.6259 - val_loss: 3.0130 - val_accuracy: 0.5836\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6470 - accuracy: 0.6259 - val_loss: 3.0183 - val_accuracy: 0.5836\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6494 - accuracy: 0.6259 - val_loss: 3.0236 - val_accuracy: 0.5836\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6518 - accuracy: 0.6259 - val_loss: 3.0277 - val_accuracy: 0.5836\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6541 - accuracy: 0.6259 - val_loss: 3.0326 - val_accuracy: 0.5836\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6563 - accuracy: 0.6259 - val_loss: 3.0362 - val_accuracy: 0.5836\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6585 - accuracy: 0.6259 - val_loss: 3.0402 - val_accuracy: 0.5836\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6606 - accuracy: 0.6259 - val_loss: 3.0437 - val_accuracy: 0.5836\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6625 - accuracy: 0.6259 - val_loss: 3.0467 - val_accuracy: 0.5836\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6644 - accuracy: 0.6259 - val_loss: 3.0499 - val_accuracy: 0.5836\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 57s 242ms/step - loss: 2.6661 - accuracy: 0.6259 - val_loss: 3.0526 - val_accuracy: 0.5836\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6679 - accuracy: 0.6259 - val_loss: 3.0550 - val_accuracy: 0.5836\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6694 - accuracy: 0.6259 - val_loss: 3.0568 - val_accuracy: 0.5836\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6708 - accuracy: 0.6259 - val_loss: 3.0588 - val_accuracy: 0.5836\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6722 - accuracy: 0.6259 - val_loss: 3.0607 - val_accuracy: 0.5836\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6735 - accuracy: 0.6259 - val_loss: 3.0625 - val_accuracy: 0.5836\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6747 - accuracy: 0.6259 - val_loss: 3.0650 - val_accuracy: 0.5836\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6759 - accuracy: 0.6259 - val_loss: 3.0658 - val_accuracy: 0.5836\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6770 - accuracy: 0.6259 - val_loss: 3.0674 - val_accuracy: 0.5836\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6780 - accuracy: 0.6259 - val_loss: 3.0688 - val_accuracy: 0.5836\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6789 - accuracy: 0.6259 - val_loss: 3.0698 - val_accuracy: 0.5836\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6798 - accuracy: 0.6259 - val_loss: 3.0715 - val_accuracy: 0.5836\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6806 - accuracy: 0.6259 - val_loss: 3.0719 - val_accuracy: 0.5836\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6813 - accuracy: 0.6259 - val_loss: 3.0732 - val_accuracy: 0.5836\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6821 - accuracy: 0.6259 - val_loss: 3.0743 - val_accuracy: 0.5836\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6827 - accuracy: 0.6259 - val_loss: 3.0746 - val_accuracy: 0.5836\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6833 - accuracy: 0.6259 - val_loss: 3.0758 - val_accuracy: 0.5836\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6840 - accuracy: 0.6259 - val_loss: 3.0768 - val_accuracy: 0.5836\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6845 - accuracy: 0.6259 - val_loss: 3.0774 - val_accuracy: 0.5836\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6850 - accuracy: 0.6259 - val_loss: 3.0775 - val_accuracy: 0.5836\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 57s 241ms/step - loss: 2.6855 - accuracy: 0.6259 - val_loss: 3.0783 - val_accuracy: 0.5836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff23039bc10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
        "encoder_model.summary()"
      ],
      "metadata": {
        "id": "kgzuUzh446Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21df7f0d-0ef5-495e-b095-ebcc5839d06a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 64)          307776    \n",
            "                                                                 \n",
            " masking (Masking)           (None, None, 64)          0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 64),              33024     \n",
            "                              (None, 64),                        \n",
            "                              (None, 64)]                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 340,800\n",
            "Trainable params: 340,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 time step의 hidden state를 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(hidden_units,))\n",
        "# 이전 time step의 cell state를 저장하는 텐서\n",
        "decoder_state_input_c = Input(shape=(hidden_units,))\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 훈련 때 사용했던 임베딩 층을 재사용\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
        "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
        "decoder_states = [state_h, state_c]"
      ],
      "metadata": {
        "id": "34aFcPvv47Wd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "id": "3IuruNmY48f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab87415-3d18-4890-d232-fbb9879fa725"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 64)     696256      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 64)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 64),   33024       ['embedding_1[1][0]',            \n",
            "                                 (None, 64),                      'input_3[0][0]',                \n",
            "                                 (None, 64)]                      'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, None, 10879)  118363520   ['lstm_1[1][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 119,092,800\n",
            "Trainable params: 119,092,800\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "metadata": {
        "id": "HVBpA_TY4-Ft"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = fra2idx['\\t']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += ' ' + sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_fra_seq_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "uQIB6OQ65DxI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
        "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print('입력 문장:', lines.eng[seq_index])\n",
        "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "metadata": {
        "id": "N6fBeAxy5FFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "403f5a29-6492-422c-f6de-890d985e91c3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4a58a91b2e0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# 입력 문장의 인덱스 (자유롭게 선택해 보세요)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdecoded_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'입력 문장:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-74517b713134>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# 예측 결과를 문자로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 249, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"model_2\" (type Functional).\n    \n    Input 0 of layer \"dense_1\" is incompatible with the layer: expected axis -1 of input shape to have value 10879, but received input with shape (None, 1, 64)\n    \n    Call arguments received:\n      • inputs=('tf.Tensor(shape=(None, 1), dtype=float32)', 'tf.Tensor(shape=(None, 64), dtype=float32)', 'tf.Tensor(shape=(None, 64), dtype=float32)')\n      • training=False\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KaC9SpUC5IOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}